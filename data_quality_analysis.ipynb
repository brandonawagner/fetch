{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb08ee7",
   "metadata": {},
   "source": [
    "# Data Quality Issues\n",
    "\n",
    "For this exerice, I will be focusing mainly on null values, duplicates, invalid data types and questionable anomalies. These issues will be discovered using both Pandas(Part 1) and SQL (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa2f72",
   "metadata": {},
   "source": [
    "## Part 1: Nulls and Duplicates (Pandas)\n",
    "\n",
    "Below I am using Pandas to search through the different JSON files. I will ferequently use the pandas info() function to view the null count and data types. This helps to determine what data types to store the columns as in the SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cc8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39edbf62",
   "metadata": {},
   "source": [
    "**Section 1**\n",
    "\n",
    "First I like to use the head() function to get a feel of the data through a quick sample. This is generally what I do first when starting to access the data. \n",
    "\n",
    "Example is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f93107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>barcode</th>\n",
       "      <th>category</th>\n",
       "      <th>categoryCode</th>\n",
       "      <th>cpg</th>\n",
       "      <th>name</th>\n",
       "      <th>topBrand</th>\n",
       "      <th>brandCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '601ac115be37ce2ead437551'}</td>\n",
       "      <td>511111019862</td>\n",
       "      <td>Baking</td>\n",
       "      <td>BAKING</td>\n",
       "      <td>{'$id': {'$oid': '601ac114be37ce2ead437550'}, ...</td>\n",
       "      <td>test brand @1612366101024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'$oid': '601c5460be37ce2ead43755f'}</td>\n",
       "      <td>511111519928</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>{'$id': {'$oid': '5332f5fbe4b03c9a25efd0ba'}, ...</td>\n",
       "      <td>Starbucks</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STARBUCKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'$oid': '601ac142be37ce2ead43755d'}</td>\n",
       "      <td>511111819905</td>\n",
       "      <td>Baking</td>\n",
       "      <td>BAKING</td>\n",
       "      <td>{'$id': {'$oid': '601ac142be37ce2ead437559'}, ...</td>\n",
       "      <td>test brand @1612366146176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TEST BRANDCODE @1612366146176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'$oid': '601ac142be37ce2ead43755a'}</td>\n",
       "      <td>511111519874</td>\n",
       "      <td>Baking</td>\n",
       "      <td>BAKING</td>\n",
       "      <td>{'$id': {'$oid': '601ac142be37ce2ead437559'}, ...</td>\n",
       "      <td>test brand @1612366146051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TEST BRANDCODE @1612366146051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'$oid': '601ac142be37ce2ead43755e'}</td>\n",
       "      <td>511111319917</td>\n",
       "      <td>Candy &amp; Sweets</td>\n",
       "      <td>CANDY_AND_SWEETS</td>\n",
       "      <td>{'$id': {'$oid': '5332fa12e4b03c9a25efd1e7'}, ...</td>\n",
       "      <td>test brand @1612366146827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TEST BRANDCODE @1612366146827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id       barcode        category  \\\n",
       "0  {'$oid': '601ac115be37ce2ead437551'}  511111019862          Baking   \n",
       "1  {'$oid': '601c5460be37ce2ead43755f'}  511111519928       Beverages   \n",
       "2  {'$oid': '601ac142be37ce2ead43755d'}  511111819905          Baking   \n",
       "3  {'$oid': '601ac142be37ce2ead43755a'}  511111519874          Baking   \n",
       "4  {'$oid': '601ac142be37ce2ead43755e'}  511111319917  Candy & Sweets   \n",
       "\n",
       "       categoryCode                                                cpg  \\\n",
       "0            BAKING  {'$id': {'$oid': '601ac114be37ce2ead437550'}, ...   \n",
       "1         BEVERAGES  {'$id': {'$oid': '5332f5fbe4b03c9a25efd0ba'}, ...   \n",
       "2            BAKING  {'$id': {'$oid': '601ac142be37ce2ead437559'}, ...   \n",
       "3            BAKING  {'$id': {'$oid': '601ac142be37ce2ead437559'}, ...   \n",
       "4  CANDY_AND_SWEETS  {'$id': {'$oid': '5332fa12e4b03c9a25efd1e7'}, ...   \n",
       "\n",
       "                        name  topBrand                      brandCode  \n",
       "0  test brand @1612366101024       0.0                            NaN  \n",
       "1                  Starbucks       0.0                      STARBUCKS  \n",
       "2  test brand @1612366146176       0.0  TEST BRANDCODE @1612366146176  \n",
       "3  test brand @1612366146051       0.0  TEST BRANDCODE @1612366146051  \n",
       "4  test brand @1612366146827       0.0  TEST BRANDCODE @1612366146827  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands = pd.read_json('/Users/brandonwagner/Desktop/brands.json',lines=True)\n",
    "brands.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3dcc2",
   "metadata": {},
   "source": [
    "**Section 2**\n",
    "\n",
    "As shown below brands have null values in category, categoryCode, topBrand and brandCode. Around 44.3% of category codes and 47.5% of top brand values are null.\n",
    "\n",
    "The Brand ID and CPG ID are not all true UUIDs which lets me know that I need to store them as TEXT/VARCHAR.\n",
    "\n",
    "The CPG ID has duplicates that we need to remove as well before storing in the CPG table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2919494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167 entries, 0 to 1166\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   _id           1167 non-null   object \n",
      " 1   barcode       1167 non-null   int64  \n",
      " 2   category      1012 non-null   object \n",
      " 3   categoryCode  517 non-null    object \n",
      " 4   name          1167 non-null   object \n",
      " 5   topBrand      555 non-null    float64\n",
      " 6   brandCode     933 non-null    object \n",
      " 7   $ref          1167 non-null   object \n",
      " 8   $id.$oid      1167 non-null   object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 82.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167 entries, 0 to 1166\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   $ref      1167 non-null   object\n",
      " 1   $id.$oid  1167 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.4+ KB\n",
      "\n",
      "Brand IDs are all UUIDs? False\n",
      "CPG IDs are UUIDs? False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$ref</th>\n",
       "      <th>$id.$oid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogs</td>\n",
       "      <td>601ac142be37ce2ead437559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cogs</td>\n",
       "      <td>601ac142be37ce2ead437559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cogs</td>\n",
       "      <td>601ac142be37ce2ead437559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cogs</td>\n",
       "      <td>559c2234e4b06aca36af13c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cogs</td>\n",
       "      <td>5332f5fbe4b03c9a25efd0ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    $ref                  $id.$oid\n",
       "3   Cogs  601ac142be37ce2ead437559\n",
       "5   Cogs  601ac142be37ce2ead437559\n",
       "6   Cogs  601ac142be37ce2ead437559\n",
       "12  Cogs  559c2234e4b06aca36af13c6\n",
       "14  Cogs  5332f5fbe4b03c9a25efd0ba"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(cpg.columns.tolist())\n",
    "#print(brands_final.columns.tolist())\n",
    "brands['_id'] = brands['_id'].apply(lambda x: x['$oid'])\n",
    "cpg = pd.json_normalize(brands['cpg'])\n",
    "\n",
    "brands_final = pd.concat([brands, cpg], axis=1)\n",
    "brands_final = brands_final.drop('cpg', axis=1)\n",
    "brands_final.info()\n",
    "cpg.info()\n",
    "\n",
    "def is_valid_uuid(value):\n",
    "    try:\n",
    "        uuid.UUID(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "# Check if all values in the column are valid UUIDs\n",
    "all_uuids = brands_final[\"_id\"].apply(is_valid_uuid).all()\n",
    "all_uuids_2 = cpg[\"$id.$oid\"].apply(is_valid_uuid).all()\n",
    "print()\n",
    "print(\"Brand IDs are all UUIDs? \" + str(all_uuids))\n",
    "print(\"CPG IDs are UUIDs? \" + str(all_uuids_2))\n",
    "\n",
    "duplicates = cpg[cpg.duplicated(subset=[\"$id.$oid\"])]\n",
    "duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fdb26f",
   "metadata": {},
   "source": [
    "**Section 3**\n",
    "\n",
    "The user.json was one of the cleaner data-sets though there are still nulls as seen below. \n",
    "\n",
    "- Duplicate IDs were noticed in the \\_id field. In Python I handle these so we do not get a PRIMARY KEY exception when inserting into the database. In main.py, I compare against all columns when considering a full duplicate. If there were situations where there were. \n",
    "- I've also confirmed that columns such as \\_id only have one data element in their JSON object as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ead080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 495 entries, 0 to 494\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   _id           495 non-null    object\n",
      " 1   active        495 non-null    bool  \n",
      " 2   createdDate   495 non-null    object\n",
      " 3   lastLogin     433 non-null    object\n",
      " 4   role          495 non-null    object\n",
      " 5   signUpSource  447 non-null    object\n",
      " 6   state         439 non-null    object\n",
      "dtypes: bool(1), object(6)\n",
      "memory usage: 23.8+ KB\n",
      "\n",
      "Keys: $oid\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_json('/Users/brandonwagner/Desktop/users.json',lines=True)\n",
    "users.info()\n",
    "duplicates = users[users.duplicated(subset=['_id'])]\n",
    "duplicates.head()\n",
    "\n",
    "df = pd.json_normalize(users['_id'])\n",
    "all_keys = df.columns.tolist()\n",
    "print()\n",
    "print(\"Keys: \" + \" \".join(all_keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c979b",
   "metadata": {},
   "source": [
    "**Section 4**\n",
    "\n",
    "Below I am looking at the receipts data to evaluate the null counts for each column. The amount of nulls in the purchaseDate, pointsEarned, and totalSpent are examples of missing values that I would need to notify the business of.\n",
    "\n",
    "I also notice that\n",
    "- The IDs aren't truly all UUIDs so I cannot store these in SQL as such\n",
    "- There are user_ids in receipts that do not exists in the user JSON, so I will not be able to add a foreign key constraint (REFERENCE) until the missing users are added to the user table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9094ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File /Users/brandonwagner/Downloads/receipts.json.gz does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m receipts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/brandonwagner/Downloads/receipts.json.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#print(receipts.columns.tolist())\u001b[39;00m\n\u001b[1;32m      4\u001b[0m receipts\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/json/_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/json/_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/json/_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    959\u001b[0m ):\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    968\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File /Users/brandonwagner/Downloads/receipts.json.gz does not exist"
     ]
    }
   ],
   "source": [
    "receipts = pd.read_json('/Users/brandonwagner/Downloads/receipts.json.gz', compression='gzip', lines=True)\n",
    "#print(receipts.columns.tolist())\n",
    "\n",
    "receipts.info()\n",
    "#null_rows = receipts[receipts['rewardsReceiptItemList'].isnull()]\n",
    "\n",
    "\n",
    "# Check if all values in the column are valid UUIDs\n",
    "receipts['_id'] = receipts['_id'].apply(lambda x: x['$oid'])\n",
    "all_uuids = receipts[\"_id\"].apply(is_valid_uuid).all()\n",
    "print()\n",
    "print(\"All IDs are UUIDs? \" + str(all_uuids))\n",
    "\n",
    "\n",
    "#user_ids in receipts that don't exists in users\n",
    "result = receipts[~receipts['_id'].isin(users['_id'])]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a902d479",
   "metadata": {},
   "source": [
    "**Section 5**\n",
    "\n",
    "Next we will check the receipt items column which is a list of JSON objects. We will transform this into normalized data by first \"exploding\" the list to get one entry per row, then \"normalizing\" the JSON objects to place each element into it's own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e05537",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts_item = receipts.explode('rewardsReceiptItemList')\n",
    "\n",
    "receipts_item = pd.json_normalize(receipts_item['rewardsReceiptItemList'])\n",
    "pd.set_option('display.max_columns', None)\n",
    "receipts_item = pd.concat([receipts[['_id']], receipts_item], axis=1)\n",
    "#print(receipts_item.columns.tolist())\n",
    "receipts_item.info()\n",
    "#null_rows = receipts_item[receipts_item['_id'].isnull()]\n",
    "#null_rows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df6793",
   "metadata": {},
   "source": [
    "**Section 6**\n",
    "\n",
    "I noticed that there were two columns that looked and sounded like they may always contain the same value pointsPayerId and rewardsProductPartnerId. I confirm that this in the case below. For data like this, we have the option to only store it in one column in SQL as to not store unnecessary duplicate data.\n",
    "\n",
    "I also will store this ID in a separate SQL table in case we are able to capture other information about the product partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5058d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compare = receipts_item[(receipts_item['pointsPayerId'] != receipts_item['rewardsProductPartnerId']) & receipts_item['pointsPayerId'].notna() & receipts_item['rewardsProductPartnerId'].notna()]\n",
    "\n",
    "print(df_compare[['pointsPayerId', 'rewardsProductPartnerId']])\n",
    "rpp = receipts_item[receipts_item['rewardsProductPartnerId'].notna()]\n",
    "rpp = rpp[['rewardsProductPartnerId']]\n",
    "rpp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421ae2b",
   "metadata": {},
   "source": [
    "## Part 2: Statistical Analysis (SQL - Postgres)\n",
    "\n",
    "We can find outlier values by finding the inter-quartile range in SQL. For an example, below I will use the point_earned column in the receipt database. I will include columns such as created date that may help figure out the culprit if it is truly invalid data.\n",
    "\n",
    "**SQL to Find Points Earned (Receipts) Outliers**\n",
    "![SQL To Find Points Earned (Receipt) Outliers](files/sql_outliers_receipt_points_earned.png)\n",
    "\n",
    "**Results - 36 questionable rows**\n",
    "![Results of SQL To Find Points Earned (Receipt) Outliers](files/sql_outliers_receipt_points_earned_results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b301e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
